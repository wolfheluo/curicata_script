#!/usr/bin/env python3
"""
PCAP åˆ†æå™¨ Web UI
åŸºæ–¼ Flask + Bootstrap 5 + Chart.js æ§‹å»ºçš„ç¶²è·¯å°åŒ…åˆ†æä»‹é¢

åŠŸèƒ½åŒ…æ‹¬ï¼š
- ä»»å‹™ç¸½è¦½ï¼šç®¡ç†åˆ†æä»»å‹™ï¼ŒæŸ¥çœ‹ç‹€æ…‹
- æµé‡è¶¨å‹¢ï¼šæŠ˜ç·šåœ–é¡¯ç¤ºæµé‡è®ŠåŒ–
- Top IPï¼šé•·æ¢åœ–èˆ‡è¡¨æ ¼å±•ç¤ºæµé‡æ’è¡Œ
- åœ‹åˆ¥çµ±è¨ˆï¼šåœ“é¤…åœ–é¡¯ç¤ºé€£ç·šä¾†æºåˆ†å¸ƒ
- äº‹ä»¶åˆ†æï¼šç¶²è·¯äº‹ä»¶çµ±è¨ˆèˆ‡ä¾†æºåˆ†æ
- ç•°å¸¸è­¦ç¤ºï¼šå®‰å…¨å¨è„…æ¸…å–®èˆ‡è©³ç´°èªªæ˜
"""

import os
import json
import glob
from datetime import datetime, timedelta
from pathlib import Path
from flask import Flask, render_template, jsonify, request, redirect, url_for, flash
import subprocess
import threading
import time
from collections import defaultdict, Counter
import ipaddress
import re


app = Flask(__name__)
app.secret_key = 'suricata_pcap_analyzer_secret_key_2025'

# é…ç½®
PCAP_DIR = "pcaps"
PROJECT_DIR = "project"
TSHARK_EXE = r"C:\Program Files\Wireshark\tshark.exe"

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
os.makedirs(PCAP_DIR, exist_ok=True)
os.makedirs(PROJECT_DIR, exist_ok=True)


def get_tasks():
    """å–å¾—æ‰€æœ‰åˆ†æä»»å‹™"""
    tasks = []
    
    # æƒæ pcaps ç›®éŒ„ä¸‹çš„è³‡æ–™å¤¾
    if os.path.exists(PCAP_DIR):
        for item in os.listdir(PCAP_DIR):
            item_path = os.path.join(PCAP_DIR, item)
            if os.path.isdir(item_path):
                # æª¢æŸ¥æ˜¯å¦æœ‰ .pcap æª”æ¡ˆ
                pcap_files = glob.glob(os.path.join(item_path, "*.pcap"))
                if pcap_files:
                    task = {
                        'name': item,
                        'path': item_path,
                        'pcap_count': len(pcap_files),
                        'created_time': datetime.fromtimestamp(os.path.getctime(item_path)),
                        'analyzed': False,
                        'total_bytes': None,
                        'total_events': None,
                        'anomaly_count': 0,
                        'start_time': None,
                        'end_time': None
                    }
                    
                    # æª¢æŸ¥æ˜¯å¦å·²åˆ†æ
                    project_dir = os.path.join(PROJECT_DIR, item)
                    summary_file = os.path.join(project_dir, "analysis_summary.json")
                    
                    if os.path.exists(summary_file):
                        try:
                            with open(summary_file, 'r', encoding='utf-8') as f:
                                summary = json.load(f)
                            
                            task['analyzed'] = True
                            task['total_bytes'] = summary.get('flow', {}).get('total_bytes', 0)
                            task['start_time'] = summary.get('flow', {}).get('start_time', '')
                            task['end_time'] = summary.get('flow', {}).get('end_time', '')
                            
                            # è¨ˆç®—ç¸½äº‹ä»¶æ•¸
                            events = summary.get('event', {})
                            total_events = sum(event.get('count', 0) for event in events.values())
                            task['total_events'] = total_events
                            
                            # è¨ˆç®—ç•°å¸¸æ•¸ï¼ˆé€™è£¡å¯ä»¥æ ¹æ“šå¯¦éš›éœ€æ±‚å®šç¾©ç•°å¸¸åˆ¤æ–·é‚è¼¯ï¼‰
                            task['anomaly_count'] = detect_anomalies(summary)
                            
                        except Exception as e:
                            print(f"è®€å–åˆ†æçµæœå¤±æ•—: {e}")
                    
                    tasks.append(task)
    
    # æŒ‰å»ºç«‹æ™‚é–“æ’åº
    tasks.sort(key=lambda x: x['created_time'], reverse=True)
    return tasks


def detect_anomalies(summary):
    """æª¢æ¸¬ç•°å¸¸è¡Œç‚ºï¼ˆç¤ºä¾‹é‚è¼¯ï¼‰"""
    anomaly_count = 0
    
    try:
        # 1. æª¢æŸ¥æ˜¯å¦æœ‰å¯ç–‘çš„å¤§æµé‡é€£æ¥
        top_ip = summary.get('top_ip', [])
        if top_ip and len(top_ip) > 0:
            # å¦‚æœæœ€å¤§æµé‡è¶…é100MBï¼Œè¦–ç‚ºå¯ç–‘
            max_bytes = top_ip[0].get('bytes', 0)
            if max_bytes > 100 * 1024 * 1024:  # 100MB
                anomaly_count += 1
        
        # 2. æª¢æŸ¥æ˜¯å¦æœ‰ç•°å¸¸å”è­°æ¯”ä¾‹
        events = summary.get('event', {})
        total_events = sum(event.get('count', 0) for event in events.values())
        
        if total_events > 0:
            # æª¢æŸ¥ TLS æµé‡æ˜¯å¦éå¤šï¼ˆè¶…éç¸½æµé‡çš„80%ï¼‰
            tls_count = events.get('TLS', {}).get('count', 0)
            if tls_count / total_events > 0.8:
                anomaly_count += 1
        
        # 3. æª¢æŸ¥æ˜¯å¦æœ‰ä¾†è‡ªå¯ç–‘åœ‹å®¶çš„å¤§é‡æµé‡
        geo = summary.get('geo', {})
        total_geo_bytes = sum(geo.values())
        
        if total_geo_bytes > 0:
            # æª¢æŸ¥éæœ¬åœ°å’Œå°ç£ä»¥å¤–çš„æµé‡æ¯”ä¾‹
            suspicious_bytes = 0
            for country, bytes_val in geo.items():
                if country not in ['LOCAL', 'TW', 'US']:  # å¯èª¿æ•´ä¿¡ä»»æ¸…å–®
                    suspicious_bytes += bytes_val
            
            if suspicious_bytes / total_geo_bytes > 0.3:  # è¶…é30%ä¾†è‡ªå…¶ä»–åœ‹å®¶
                anomaly_count += 1
        
    except Exception as e:
        print(f"ç•°å¸¸æª¢æ¸¬éŒ¯èª¤: {e}")
    
    return anomaly_count


def run_analysis(task_name):
    """åŸ·è¡Œåˆ†æä»»å‹™"""
    def analysis_thread():
        try:
            print(f"é–‹å§‹åˆ†æä»»å‹™: {task_name}")
            
            # æº–å‚™åŸ·è¡Œ 2.tshark.py
            pcap_path = os.path.join(PCAP_DIR, task_name)
            
            # ä½¿ç”¨ subprocess åŸ·è¡Œåˆ†æè…³æœ¬
            result = subprocess.run([
                'python', '2.tshark.py'
            ], input=f"{task_name}\n{pcap_path}\n", 
               text=True, capture_output=True)
            
            if result.returncode == 0:
                print(f"åˆ†æä»»å‹™ {task_name} å®Œæˆ")
            else:
                print(f"åˆ†æä»»å‹™ {task_name} å¤±æ•—: {result.stderr}")
                
        except Exception as e:
            print(f"åŸ·è¡Œåˆ†æä»»å‹™å¤±æ•—: {e}")
    
    # åœ¨èƒŒæ™¯åŸ·è¡Œåˆ†æ
    thread = threading.Thread(target=analysis_thread)
    thread.daemon = True
    thread.start()


@app.route('/')
def index():
    """ä»»å‹™ç¸½è¦½é é¢"""
    tasks = get_tasks()
    return render_template('index.html', tasks=tasks)


@app.route('/analyze/<task_name>')
def analyze_task(task_name):
    """é–‹å§‹åˆ†æä»»å‹™"""
    # æª¢æŸ¥ä»»å‹™æ˜¯å¦å­˜åœ¨
    tasks = get_tasks()
    task = next((t for t in tasks if t['name'] == task_name), None)
    
    if not task:
        flash('ä»»å‹™ä¸å­˜åœ¨', 'error')
        return redirect(url_for('index'))
    
    # å¦‚æœå·²ç¶“åˆ†æéï¼Œç›´æ¥è·³åˆ°çµæœé é¢
    if task['analyzed']:
        return redirect(url_for('dashboard', task_name=task_name))
    
    # é–‹å§‹åˆ†æ
    run_analysis(task_name)
    flash(f'å·²é–‹å§‹åˆ†æä»»å‹™ã€Œ{task_name}ã€ï¼Œè«‹ç¨å¾Œé‡æ–°æ•´ç†æŸ¥çœ‹çµæœ', 'success')
    return redirect(url_for('index'))


@app.route('/dashboard/<task_name>')
def dashboard(task_name):
    """åˆ†æçµæœå„€è¡¨æ¿"""
    # æª¢æŸ¥åˆ†æçµæœæ˜¯å¦å­˜åœ¨
    summary_file = os.path.join(PROJECT_DIR, task_name, "analysis_summary.json")
    
    if not os.path.exists(summary_file):
        flash('åˆ†æçµæœä¸å­˜åœ¨ï¼Œè«‹å…ˆé€²è¡Œåˆ†æ', 'error')
        return redirect(url_for('index'))
    
    return render_template('dashboard.html', task_name=task_name)


# API è·¯ç”±ï¼šæä¾›åˆ†æè³‡æ–™çµ¦å‰ç«¯JavaScript

@app.route('/api/flow/<task_name>')
def api_flow(task_name):
    """æµé‡è¶¨å‹¢ API"""
    try:
        summary_file = os.path.join(PROJECT_DIR, task_name, "analysis_summary.json")
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary = json.load(f)
        
        flow_data = summary.get('flow', {})
        return jsonify(flow_data)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/top_ip/<task_name>')
def api_top_ip(task_name):
    """Top IP API"""
    try:
        summary_file = os.path.join(PROJECT_DIR, task_name, "analysis_summary.json")
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary = json.load(f)
        
        top_ip_data = summary.get('top_ip', [])
        return jsonify(top_ip_data)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/geo/<task_name>')
def api_geo(task_name):
    """åœ‹åˆ¥çµ±è¨ˆ API"""
    try:
        summary_file = os.path.join(PROJECT_DIR, task_name, "analysis_summary.json")
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary = json.load(f)
        
        geo_data = summary.get('geo', {})
        return jsonify(geo_data)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/events/<task_name>')
def api_events(task_name):
    """äº‹ä»¶çµ±è¨ˆ API"""
    try:
        summary_file = os.path.join(PROJECT_DIR, task_name, "analysis_summary.json")
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary = json.load(f)
        
        events_data = summary.get('event', {})
        return jsonify(events_data)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/event_details/<task_name>/<protocol>')
def api_event_details(task_name, protocol):
    """å”è­°è©³ç´°çµ±è¨ˆ API"""
    try:
        summary_file = os.path.join(PROJECT_DIR, task_name, "analysis_summary.json")
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary = json.load(f)
        
        events_data = summary.get('event', {})
        protocol_data = events_data.get(protocol, {})
        
        if not protocol_data:
            return jsonify({'error': f'æ‰¾ä¸åˆ°å”è­° {protocol} çš„è³‡æ–™'}), 404
        
        result = {
            'protocol': protocol,
            'total_count': protocol_data.get('count', 0),
            'top_connections': protocol_data.get('detailed_stats', [])
        }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/anomaly/<task_name>')
def api_anomaly(task_name):
    """ç•°å¸¸è­¦ç¤º API"""
    try:
        summary_file = os.path.join(PROJECT_DIR, task_name, "analysis_summary.json")
        with open(summary_file, 'r', encoding='utf-8') as f:
            summary = json.load(f)
        
        # ç”Ÿæˆç•°å¸¸è­¦ç¤ºè³‡æ–™
        anomalies = generate_anomaly_alerts(summary)
        return jsonify(anomalies)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


def generate_anomaly_alerts(summary):
    """ç”Ÿæˆç•°å¸¸è­¦ç¤ºè³‡æ–™"""
    alerts = []
    
    try:
        # 1. å¤§æµé‡é€£æ¥è­¦ç¤º
        top_ip = summary.get('top_ip', [])
        for i, conn in enumerate(top_ip[:5]):  # æª¢æŸ¥å‰5å
            bytes_val = conn.get('bytes', 0)
            if bytes_val > 50 * 1024 * 1024:  # è¶…é50MB
                # è§£æé€£æ¥å­—ä¸²
                connection = conn.get('connection', '')
                if ' -> ' in connection:
                    src_part, dst_part = connection.split(' -> ')
                    src_ip = src_part.split(':')[0] if ':' in src_part else src_part
                    
                    alerts.append({
                        'type': 'high_traffic',
                        'severity': 'high' if bytes_val > 200 * 1024 * 1024 else 'medium',
                        'title': 'å¤§æµé‡é€£æ¥è­¦ç¤º',
                        'description': f'åµæ¸¬åˆ°ç•°å¸¸å¤§æµé‡é€£æ¥ï¼š{format_bytes(bytes_val)}',
                        'ip': src_ip,
                        'connection': connection,
                        'time': summary.get('flow', {}).get('start_time', ''),
                        'details': {
                            'bytes': bytes_val,
                            'rank': i + 1,
                            'percentage': round((bytes_val / summary.get('flow', {}).get('total_bytes', 1)) * 100, 2)
                        }
                    })
        
        # 2. ç•°å¸¸å”è­°æ¯”ä¾‹è­¦ç¤º
        events = summary.get('event', {})
        total_events = sum(event.get('count', 0) for event in events.values())
        
        if total_events > 0:
            for protocol, event_data in events.items():
                count = event_data.get('count', 0)
                percentage = (count / total_events) * 100
                
                # æª¢æŸ¥æ˜¯å¦æœ‰ç•°å¸¸æ¯”ä¾‹
                if protocol == 'OTHER' and percentage > 50:
                    alerts.append({
                        'type': 'protocol_anomaly',
                        'severity': 'medium',
                        'title': 'æœªè­˜åˆ¥å”è­°éå¤š',
                        'description': f'æœªè­˜åˆ¥å”è­°ä½”ç¸½æµé‡ {percentage:.1f}%ï¼Œå¯èƒ½å­˜åœ¨æƒ¡æ„æµé‡',
                        'ip': event_data.get('top_ip', ''),
                        'time': summary.get('flow', {}).get('start_time', ''),
                        'details': {
                            'protocol': protocol,
                            'count': count,
                            'percentage': round(percentage, 2)
                        }
                    })
                
                elif protocol in ['TLS', 'TCP'] and percentage > 70:
                    alerts.append({
                        'type': 'protocol_anomaly',
                        'severity': 'low',
                        'title': f'{protocol} å”è­°æµé‡éå¤š',
                        'description': f'{protocol} å”è­°ä½”ç¸½æµé‡ {percentage:.1f}%ï¼Œå»ºè­°é€²ä¸€æ­¥æª¢æŸ¥',
                        'ip': event_data.get('top_ip', ''),
                        'time': summary.get('flow', {}).get('start_time', ''),
                        'details': {
                            'protocol': protocol,
                            'count': count,
                            'percentage': round(percentage, 2)
                        }
                    })
        
        # 3. å¯ç–‘åœ‹å®¶æµé‡è­¦ç¤º
        geo = summary.get('geo', {})
        total_geo_bytes = sum(geo.values())
        
        if total_geo_bytes > 0:
            suspicious_countries = []
            for country, bytes_val in geo.items():
                percentage = (bytes_val / total_geo_bytes) * 100
                
                # å®šç¾©å¯ç–‘åœ‹å®¶æ¸…å–®ï¼ˆå¯æ ¹æ“šéœ€æ±‚èª¿æ•´ï¼‰
                if country in ['RU', 'CN', 'KP', 'IR'] and percentage > 5:
                    suspicious_countries.append({
                        'country': country,
                        'bytes': bytes_val,
                        'percentage': percentage
                    })
            
            if suspicious_countries:
                for country_info in suspicious_countries:
                    alerts.append({
                        'type': 'geo_anomaly',
                        'severity': 'medium',
                        'title': 'å¯ç–‘åœ‹å®¶æµé‡è­¦ç¤º',
                        'description': f'åµæ¸¬åˆ°ä¾†è‡ª {country_info["country"]} çš„å¤§é‡æµé‡ï¼š{format_bytes(country_info["bytes"])} ({country_info["percentage"]:.1f}%)',
                        'ip': '',
                        'time': summary.get('flow', {}).get('start_time', ''),
                        'details': {
                            'country': country_info['country'],
                            'bytes': country_info['bytes'],
                            'percentage': round(country_info['percentage'], 2)
                        }
                    })
        
        # 4. æ™‚é–“ç•°å¸¸è­¦ç¤ºï¼ˆæ·±å¤œå¤§æµé‡ï¼‰
        per_10_minutes = summary.get('flow', {}).get('per_10_minutes', {})
        if per_10_minutes:
            for time_str, bytes_val in per_10_minutes.items():
                try:
                    # è§£ææ™‚é–“
                    time_obj = datetime.strptime(time_str, '%Y-%m-%d %H:%M')
                    hour = time_obj.hour
                    
                    # æª¢æŸ¥æ˜¯å¦ç‚ºæ·±å¤œæ™‚æ®µï¼ˆ22:00-06:00ï¼‰ä¸”æµé‡éå¤§
                    if (hour >= 22 or hour <= 6) and bytes_val > 100 * 1024 * 1024:  # 100MB
                        alerts.append({
                            'type': 'time_anomaly',
                            'severity': 'medium',
                            'title': 'æ·±å¤œç•°å¸¸æµé‡',
                            'description': f'åœ¨ {time_str} åµæ¸¬åˆ°ç•°å¸¸å¤§æµé‡ï¼š{format_bytes(bytes_val)}',
                            'ip': '',
                            'time': time_str,
                            'details': {
                                'time_period': time_str,
                                'bytes': bytes_val,
                                'hour': hour
                            }
                        })
                except ValueError:
                    continue
    
    except Exception as e:
        print(f"ç”Ÿæˆç•°å¸¸è­¦ç¤ºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    return alerts


def format_bytes(bytes_val):
    """æ ¼å¼åŒ–ä½å…ƒçµ„å¤§å°"""
    if bytes_val == 0:
        return '0 B'
    
    units = ['B', 'KB', 'MB', 'GB', 'TB']
    unit_index = 0
    
    while bytes_val >= 1024 and unit_index < len(units) - 1:
        bytes_val /= 1024
        unit_index += 1
    
    return f"{bytes_val:.1f} {units[unit_index]}"


def generate_ten_minute_stats(per_minute_data, start_time, end_time):
    """å¾æ¯åˆ†é˜è³‡æ–™ç”Ÿæˆæ¯10åˆ†é˜çµ±è¨ˆ"""
    if not per_minute_data or not start_time or not end_time:
        return {}
    
    try:
        start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
        end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))
    except:
        return {}
    
    per_10_minutes = {}
    
    for time_str, bytes_val in per_minute_data.items():
        try:
            # è§£ææ™‚é–“
            time_dt = datetime.strptime(time_str, '%Y-%m-%d %H:%M')
            
            # è¨ˆç®—10åˆ†é˜é‚Šç•Œ
            minute_boundary = (time_dt.minute // 10) * 10
            boundary_dt = time_dt.replace(minute=minute_boundary, second=0, microsecond=0)
            boundary_str = boundary_dt.strftime('%Y-%m-%d %H:%M')
            
            if boundary_str not in per_10_minutes:
                per_10_minutes[boundary_str] = 0
            
            per_10_minutes[boundary_str] += bytes_val
            
        except ValueError:
            continue
    
    return per_10_minutes


def get_sorted_flow_data(flow_data, start_time, end_time):
    """ç”Ÿæˆæ’åºå¾Œçš„æµé‡è³‡æ–™ç”¨æ–¼åœ–è¡¨é¡¯ç¤º"""
    if not flow_data:
        return {'labels': [], 'values': []}
    
    # æŒ‰æ™‚é–“æ’åº
    sorted_items = sorted(flow_data.items())
    
    labels = []
    values = []
    
    for time_str, bytes_val in sorted_items:
        try:
            # æ ¼å¼åŒ–æ™‚é–“æ¨™ç±¤ï¼ˆåªé¡¯ç¤ºæ™‚é–“éƒ¨åˆ†ï¼‰
            time_obj = datetime.strptime(time_str, '%Y-%m-%d %H:%M')
            formatted_time = time_obj.strftime('%H:%M')
            labels.append(formatted_time)
            values.append(bytes_val)
        except ValueError:
            continue
    
    return {'labels': labels, 'values': values}


if __name__ == '__main__':
    print("ğŸŒ å•Ÿå‹• PCAP åˆ†æå™¨ Web UI")
    print("ğŸ“‹ åŠŸèƒ½æ¸…å–®ï¼š")
    print("   âœ… ä»»å‹™ç¸½è¦½ - ç®¡ç†åˆ†æä»»å‹™ï¼ŒæŸ¥çœ‹ç‹€æ…‹")
    print("   ğŸ“ˆ æµé‡è¶¨å‹¢ - æŠ˜ç·šåœ–é¡¯ç¤ºæµé‡è®ŠåŒ–")
    print("   ğŸ† Top IP - é•·æ¢åœ–èˆ‡è¡¨æ ¼å±•ç¤ºæµé‡æ’è¡Œ")
    print("   ğŸŒ åœ‹åˆ¥çµ±è¨ˆ - åœ“é¤…åœ–é¡¯ç¤ºé€£ç·šä¾†æºåˆ†å¸ƒ")
    print("   ğŸ” äº‹ä»¶åˆ†æ - ç¶²è·¯äº‹ä»¶çµ±è¨ˆèˆ‡ä¾†æºåˆ†æ")
    print("   ğŸš¨ ç•°å¸¸è­¦ç¤º - å®‰å…¨å¨è„…æ¸…å–®èˆ‡è©³ç´°èªªæ˜")
    print("\nğŸš€ æ­£åœ¨å•Ÿå‹•ä¼ºæœå™¨...")
    print("ğŸ”— è«‹åœ¨ç€è¦½å™¨ä¸­é–‹å•Ÿ: http://localhost:5000")
    
    app.run(host='0.0.0.0', port=5000, debug=True)
